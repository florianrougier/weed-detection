{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "weed-detection.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/florianrougier/weed-detection/blob/master/weed_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-T4V6J3iaGf",
        "colab_type": "text"
      },
      "source": [
        "## Getting the dataset from kaggle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwMnzPtZij_z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!ls ~/.kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8g62SYLDimFo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls -l ~/.kaggle\n",
        "!cat ~/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6bNKcycin5Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q kaggle\n",
        "!pip install -q kaggle-cli"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tsk7rjckippS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!kaggle datasets list -s \"weed\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29DDYsevirl7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!kaggle datasets download fpeccia/weed-detection-in-soybean-crops --unzip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "id": "cCdIvvT-59qL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import cv2\n",
        "import glob"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "bGZ4CF3m59qN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_dir = r'/dataset/dataset' # Setting the dataset directory\n",
        "classes = ['broadleaf', 'grass', 'soil', 'soybean'] # Setting all the available classes\n",
        "\n",
        "num_file = 1100 # Number of files\n",
        "all_files = []\n",
        "num_data = num_file * len(classes)\n",
        "Y = np.zeros(num_data) # Initialize all output values with 0\n",
        "\n",
        "# Get the files\n",
        "for i, cls in enumerate(classes):\n",
        "  all_files += [f for f in glob.glob(data_dir + cls + '/*.tif')][:num_file]\n",
        "  Y[i * num_file: (i + 1) * num_file] = i # Label all classes with int [0.. len(classes)]\n",
        "\n",
        "image_width = 200\n",
        "image_height = 200\n",
        "image_channel = 3\n",
        "dimension = image_width * image_height * image_channel\n",
        "\n",
        "X = np.ndarray(shape=(num_data, image_width, image_height, image_channel), dtype=np.uint8) # Create a nd array\n",
        "\n",
        "for i, file in enumerate(all_files):\n",
        "  X[i] = cv2.resize(cv2.imread(file), (image_width, image_height)) # Add and load all images\n",
        "\n",
        "# Split training, validation and testing set by creating empty arrays\n",
        "X_train = np.empty(shape=(4000, image_width, image_height, image_channel), dtype=np.uint8)\n",
        "X_val = np.empty(shape=(200, image_width, image_height, image_channel), dtype=np.uint8)\n",
        "X_test = np.empty(shape=(200, image_width, image_height, image_channel), dtype=np.uint8)\n",
        "\n",
        "Y_train = np.empty(4000)\n",
        "Y_val = np.empty(200)\n",
        "Y_test = np.empty(200)\n",
        "\n",
        "# Set all x and y values\n",
        "for i, cls in enumerate(classes):\n",
        "  X_test[50 * i: 50 * (i + 1)] = X[np.where(Y == i)[0][:50]]\n",
        "  X_val[50 * i: 50 * (i + 1)] = X[np.where(Y == i)[0][50:100]]\n",
        "  X_train[1000 * i: 1000 * (i + 1)] = X[np.where(Y == i)[0][100:]]\n",
        "\n",
        "  Y_test[50 * i: 50 * (i + 1)] = i\n",
        "  Y_val[50 * i: 50 * (i + 1)] = i\n",
        "  Y_train[1000 * i: 1000 * (i + 1)] = i\n",
        "\n",
        "# Save some memory by deleting X and Y\n",
        "del Y\n",
        "del X\n",
        "\n",
        "# Select random x and y train data\n",
        "train_indexes = np.random.permutation(X_train.shape[0]) # Create random indexes array with the length of X_train.shape[0]\n",
        "Y_train = Y_train[train_indexes].astype(int) \n",
        "X_train = X_train[train_indexes]\n",
        "\n",
        "# Reshape the train, test, val data\n",
        "X_train = np.reshape(X_train, (X_train.shape[0], -1)).astype('float64')\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], -1)).astype('float64')\n",
        "X_val = np.reshape(X_val, (X_val.shape[0], -1)).astype('float64')\n",
        "\n",
        "# Create custom tiny dataset for testing\n",
        "X_tiny = X_train[100:110].astype('float64')\n",
        "Y_tiny = Y_train[100:110].astype(int)\n",
        "num_dev = 500\n",
        "\n",
        "# Create custom dev dataset for testing\n",
        "X_dev = X_train[0:num_dev].astype('float64')\n",
        "Y_dev = Y_train[0:num_dev].astype(int)\n",
        "\n",
        "# Compute the mean image\n",
        "mean_image = np.mean(X_train, axis=0) # axis=0. stack horizontally\n",
        "# Subtract the mean image from train and test data \n",
        "X_train -= mean_image\n",
        "X_val -= mean_image \n",
        "X_test -= mean_image\n",
        "X_dev -= mean_image\n",
        "X_tiny -= mean_image\n",
        "\n",
        "print(\"X_train shape\", X_train.shape)\n",
        "print(\"X_test shape\", X_test.shape)\n",
        "print(\"X_val shape\", X_val.shape)\n",
        "print(\"X_dev shape\", X_dev.shape)\n",
        "print(\"X_tiny shape\", X_tiny.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "gnL1kSFL59qS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.rcParams['figure.figsize'] = (12.0, 8.0)\n",
        "plt.rcParams['image.interpolation'] = 'nearest'\n",
        "plt.rcParams['image.cmap'] = 'gray'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "omFoLfbn59qV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classes = ['broadleaf', 'grass', 'soil', 'soybean']\n",
        "n_class = len(classes)\n",
        "samples_per_class = 4\n",
        "\n",
        "# Plot 4 images of each class\n",
        "for Y, cls in enumerate(classes):\n",
        "  indexes = np.flatnonzero(Y == Y_train)\n",
        "  indexes = np.random.choice(indexes, samples_per_class, replace=False)\n",
        "  for i, index, in enumerate(indexes):\n",
        "    plt_index = i * n_class + Y + 1\n",
        "    plt.subplot(samples_per_class, n_class, plt_index)\n",
        "    plt.imshow(X_train[index].reshape(image_width, image_height, image_channel).astype('uint8'))\n",
        "    if i == 0: plt.title(cls)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "x4yO3Jnv59qb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NeuralNetwork:\n",
        "  hidden_size = 200\n",
        "  input_size = image_width * image_height * image_channel\n",
        "  output_size = n_class\n",
        "\n",
        "  \"\"\"\n",
        "  w1: first layer weight\n",
        "  w2: second layer weight\n",
        "  \"\"\"\n",
        "  w1 = 1e-3 * np.random.randn(input_size, hidden_size)\n",
        "  b1 = np.zeros(hidden_size)\n",
        "  w2 = 1e-3 * np.random.randn(hidden_size, output_size)\n",
        "  b2 = np.zeros(output_size)\n",
        "    \n",
        "  alpha = 1e-5\n",
        "  batch_size = 100\n",
        "    \n",
        "  epochs = 500\n",
        "  \n",
        "  def train(self, X, Y, X_val, Y_val):\n",
        "    N, D = X.shape\n",
        "    N_val = X_val.shape[0]\n",
        "    iteration_per_epoch = max(N / self.batch_size, 1)\n",
        "\n",
        "    loss_hist = []\n",
        "    train_acc_hist = []\n",
        "    val_acc_hist = []\n",
        "    \n",
        "    for it in range(self.epochs):\n",
        "      sampling = np.random.choice(np.arange(N), self.batch_size, replace=False) # Create random array data\n",
        "\n",
        "      # Getting batches for x and y\n",
        "      X_batch = X[sampling]\n",
        "      Y_batch = Y[sampling]\n",
        "\n",
        "      loss, grads = self.loss(X_batch, Y=Y_batch)\n",
        "      loss_hist.append(loss)\n",
        "\n",
        "      # Make the model learning and reshape the parameters of the network\n",
        "      self.w1 += -1.0 * self.alpha * grads['w1']\n",
        "      self.b1 += -1.0 * self.alpha * grads['b1']\n",
        "      self.w2 += -1.0 * self.alpha * grads['w2']\n",
        "      self.b2 += -1.0 * self.alpha * grads['b2']\n",
        "\n",
        "      if it % 10 == 0:\n",
        "        print('iteration: %d / %d | Loss: %f' % (it, self.epochs, loss))\n",
        "    \n",
        "      if it % iteration_per_epoch == 0:\n",
        "        train_acc = (self.predict(X_batch) == Y_batch).mean()\n",
        "        val_acc = (self.predict(X_val) == Y_val).mean()\n",
        "        train_acc_hist.append(train_acc)\n",
        "        val_acc_hist.append(val_acc)\n",
        "\n",
        "        self.alpha *= 0.95\n",
        "    \n",
        "    return {\n",
        "        'loss_hist': loss_hist,\n",
        "        'train_acc_hist': train_acc_hist,\n",
        "        'val_acc_hist': val_acc_hist\n",
        "    }\n",
        "\n",
        "  def relu(self, z):\n",
        "    return np.maximum(0, z)\n",
        "  \n",
        "  def predict(self, X):\n",
        "    Y_pred = None\n",
        "    layer1 = self.relu(X.dot(self.w1) + self.b1)\n",
        "    scores = layer1.dot(self.w2) + self.b2\n",
        "    Y_pred = np.argmax(scores, axis=1)\n",
        "    return Y_pred\n",
        "\n",
        "  def loss(self, X, Y = None):\n",
        "    N, D = X.shape\n",
        "\n",
        "    # Calculate the loss of our layer1\n",
        "    layer1 = self.relu(X.dot(self.w1) + self.b1)\n",
        "    scores = layer1.dot(self.w2) + self.b2\n",
        "\n",
        "    if (Y is None):\n",
        "      return scores\n",
        "\n",
        "    # Calculate the actual loss\n",
        "    scores -= scores.max()\n",
        "    scores = np.exp(scores)\n",
        "    scores_sumexp = np.sum(scores, axis=1)\n",
        "    softmax = scores / scores_sumexp.reshape(N, 1)\n",
        "    loss = -1.0 * np.sum(np.log(softmax[range(N), Y]))\n",
        "    loss /= N\n",
        "\n",
        "    grads = {}\n",
        "    correct_class_scores = scores[range(N), Y]\n",
        "    softmax[range(N), Y] = -1.0 * (scores_sumexp - correct_class_scores) / scores_sumexp\n",
        "    softmax /= N\n",
        "\n",
        "    grads['w2'] = layer1.T.dot(softmax)\n",
        "    grads['b2'] = np.sum(softmax, axis=0)\n",
        "\n",
        "    hidden = softmax.dot(self.w2.T)\n",
        "\n",
        "    grads['w1'] = X.T.dot(hidden)\n",
        "    grads['b1'] = np.sum(hidden, axis=0)\n",
        "\n",
        "    return loss, grads"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "7J2wgJKr59qd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nn = NeuralNetwork()\n",
        "stats = nn.train(X_dev, Y_dev, X_val, Y_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "zvUGgvty59qg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print((nn.predict(X_test) == Y_test).mean())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "E3Fn_QS659qk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "index = np.flatnonzero(0 == Y_train)\n",
        "index = np.random.choice(index, 1, replace=False)\n",
        "prediction = nn.predict(X_train[index])\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title('{} | {}'.format(classes[0], classes[prediction[0]]))\n",
        "plt.imshow(X_train[index].reshape(image_width, image_height, image_channel).astype('uint8'))\n",
        "\n",
        "index = np.flatnonzero(1 == Y_train)\n",
        "index = np.random.choice(index, 1, replace=False)\n",
        "prediction = nn.predict(X_train[index])\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title('{} | {}'.format(classes[1], classes[prediction[0]]))\n",
        "plt.imshow(X_train[index].reshape(image_width, image_height, image_channel).astype('uint8'))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}